=====================
Key Papers in Safe RL
=====================

What follows is a list of papers in Safe RL that are worth reading. This is *far* from comprehensive, but should provide a useful starting point for someone looking to do research in the field.

.. contents:: Table of Contents
    :depth: 2
    

1. General Review
=================

#. `Unsolved Problems in ML Safety <https://arxiv.org/pdf/2109.13916.pdf>`_, Hendrycks et al, 2022.
#. `Concrete Problems in AI Safety <https://arxiv.org/pdf/1606.06565.pdf>`_, Amodei et al, 2016.
#. `A Comprehensive Survey on Safe Reinforcement Learning <https://www.jmlr.org/papers/volume16/garcia15a/garcia15a.pdf>`_, Garc√≠a et al, 2015.


2. Model-free RL
================

#. `Constrained Policy Optimization <http://proceedings.mlr.press/v70/achiam17a/achiam17a.pdf>`_, Achiam et al, 2017.

#. `Lyapunov-based Safe Policy Optimization for Continuous Control <https://openreview.net/pdf?id=SJgUYBVLsN>`_, Chow et al, 2019

#. `Batch Policy Learning under Constraints <http://proceedings.mlr.press/v97/le19a/le19a.pdf>`_, Le et al, 2019 


#. `Reward Constrained Policy Optimization <https://openreview.net/pdf?id=SkfrvsA9FX>`_, Tessler et all, 2019

#. `Responsive Safety in Reinforcement Learning by PID Lagrangian Methods <http://proceedings.mlr.press/v119/stooke20a/stooke20a.pdf>`_, Stooke et al, 2020

#. `Projection-based Constrained Policy Optimization <https://openreview.net/pdf?id=rke3TJrtPS>`_, Yang et al, 2020.



3. Model-based RL
=================

#. `Safe Model-based Reinforcement Learning with Stability Guarantees <https://proceedings.neurips.cc/paper/2017/file/766ebcd59621e305170616ba3d3dac32-Paper.pdf>`_, Berkenkamp et al, 2017 

#. `Constrained model predictive control: Stability and optimality <https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.231.3109&rep=rep1&type=pdf>`_, Mayne et al, 2000

#. `Constrained Policy Optimization via Bayesian World Models <https://arxiv.org/pdf/2201.09802.pdf>`_, As et al, 2022


4. Transfer Learning
====================

#. `Learning to be Safe: Deep RL with a Safety Critic <https://arxiv.org/pdf/2010.14603.pdf>`_, Srinivasan et al, 2020


5. Ensemble Learning
====================

#. `Gerneralzieing from a Few Environments in Safety-critical Reinforcement Learning <https://arxiv.org/pdf/1907.01475.pdf>`_, Kenton et al, 2019

#. `Leave No Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning <https://openreview.net/pdf?id=S1vuO-bCW>`_, Eysenbach et al, 2018


6. Human in The Loop
====================

#. `Trial without Error: Towards Safe Reinforcement Learning via Human Intervention <http://arxiv.org/abs/1707.05173>`_, Saunders et al, 2017


7. Curriculum Learning
======================

#. `Safe Reinforcement Learning via Curriculum Induction <https://proceedings.neurips.cc/paper/2020/file/8df6a65941e4c9da40a4fb899de65c55-Paper.pdf>`_, Turchetta et al, 2020


8. Risk-sensitive RL
====================

#. `Risk-Sensitive Reinforcement Learning Applied to Control under Constraints <https://www.aaai.org/Papers/JAIR/Vol24/JAIR-2403.pdf>`_, Geibel et al, 2005

#. `Risk-Aware Transfer in Reinforcement Learning using Successor Features <https://proceedings.neurips.cc/paper/2021/file/90610aa0e24f63ec6d2637e06f9b9af2-Paper.pdf>`_, Gimelfarb et al, 2021

#. `Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive Reinforcement Learning <https://proceedings.neurips.cc/paper/2021/file/ab6439fa2daf0246f92eea433bca5ac4-Paper.pdf>`_, Fei et al, 2021


9. Formal Methods
=================

#. `Verifiably Safe Exploration for End-to-End Reinforcement Learning <https://dl.acm.org/doi/pdf/10.1145/3447928.3456653>`_, Hunt et al, 2021. See `Guarantee Safety in Training and Testing <https://vsrl-experiment.mybluemix.net/>` for related work.

